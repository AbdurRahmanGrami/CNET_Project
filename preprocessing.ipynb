{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c0f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2059408, 93)\n",
      "Labels shape: (2059408,)\n",
      "Classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "Class distribution:\n",
      "  Class 0: 1718707 samples\n",
      "  Class 1: 1563 samples\n",
      "  Class 2: 102411 samples\n",
      "  Class 3: 8229 samples\n",
      "  Class 4: 138279 samples\n",
      "  Class 5: 4182 samples\n",
      "  Class 6: 4308 samples\n",
      "  Class 7: 4746 samples\n",
      "  Class 8: 9 samples\n",
      "  Class 9: 29 samples\n",
      "  Class 10: 72655 samples\n",
      "  Class 11: 2575 samples\n",
      "  Class 12: 1176 samples\n",
      "  Class 13: 17 samples\n",
      "  Class 14: 522 samples\n",
      "\n",
      "Missing values per column (first 10):\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "       count          mean  std       min       25%       50%       75%  \\\n",
      "0  2059408.0 -2.516941e-17  1.0 -0.452141 -0.449333 -0.447903 -0.428671   \n",
      "1  2059408.0  1.918327e-17  1.0 -0.464741 -0.464735 -0.463344 -0.315312   \n",
      "2  2059408.0 -1.380091e-18  1.0 -0.011537 -0.010301 -0.010301 -0.006594   \n",
      "3  2059408.0  1.138575e-19  1.0 -0.010837 -0.009908 -0.008980 -0.006194   \n",
      "4  2059408.0 -3.301868e-18  1.0 -0.053657 -0.052588 -0.047777 -0.024705   \n",
      "5  2059408.0  5.710128e-19  1.0 -0.007565 -0.007562 -0.007502 -0.007212   \n",
      "6  2059408.0 -1.637133e-17  1.0 -0.303227 -0.295222 -0.249859 -0.036384   \n",
      "7  2059408.0  2.408259e-17  1.0 -0.321344 -0.321344 -0.222514  0.288109   \n",
      "8  2059408.0  4.801682e-17  1.0 -0.324485 -0.293542 -0.138828 -0.056313   \n",
      "9  2059408.0 -1.529486e-17  1.0 -0.257355 -0.257355 -0.257355 -0.014247   \n",
      "\n",
      "           max  \n",
      "0     3.019930  \n",
      "1     2.970089  \n",
      "2   271.534823  \n",
      "3   271.072239  \n",
      "4  1149.089024  \n",
      "5   268.887359  \n",
      "6    32.812061  \n",
      "7    37.975326  \n",
      "8    30.313500  \n",
      "9    23.940008  \n",
      "\n",
      "Zero-variance features:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "X = np.load(\"X_train.npy\")      # replace with your file names\n",
    "y = np.load(\"Y_train.npy\")\n",
    "\n",
    "print(\"Shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "print(\"Classes:\", np.unique(y))\n",
    "print(\"Class distribution:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  Class {u}: {c} samples\")\n",
    "    \n",
    "# Convert to DataFrame for easy EDA\n",
    "df = pd.DataFrame(X)\n",
    "\n",
    "df = df.drop(columns=[31, 33, 56, 57, 58, 59, 60, 61])\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column (first 10):\")\n",
    "print(df.isna().sum().head(10))\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe().transpose().head(10))\n",
    "\n",
    "# Look for constant or near-constant features\n",
    "print(\"\\nZero-variance features:\")\n",
    "zero_var = df.nunique()\n",
    "print(zero_var[zero_var <= 1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb3a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = np.load(\"X_train.npy\")\n",
    "y = np.load(\"Y_train.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ed3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_names.txt\", \"r\") as f:\n",
    "    feature_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "labels = pd.Series(y, name=\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ef1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = df.var()\n",
    "zero_var_cols = variance[variance == 0].index.tolist()\n",
    "\n",
    "df = df.drop(columns=zero_var_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28152e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.clip(-5, 5)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_clean = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cd8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c13732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.07988208184693187, 1: 87.86805333333334, 2: 1.340612807023968, 3: 16.684652387462656, 4: 0.9928773100229308, 5: 32.82578202829249, 6: 31.873205649061713, 7: 28.926801861118427, 8: 15690.72380952381, 9: 4775.43768115942, 10: 1.889668065973895, 11: 53.317993527508094, 12: 116.72164364151612, 13: 7845.361904761905, 14: 262.76331738437}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = {cls: w for cls, w in zip(classes, class_weights)}\n",
    "print(class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb149a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 889. MiB for an array with shape (1371519, 85) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      3\u001b[0m sm \u001b[38;5;241m=\u001b[39m SMOTETomek(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m      6\u001b[0m rare_classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m13\u001b[39m]\n\u001b[0;32m      8\u001b[0m y_resampled \u001b[38;5;241m=\u001b[39m y_resampled\u001b[38;5;241m.\u001b[39mreplace(rare_classes, \u001b[38;5;241m99\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:105\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    111\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_tomek.py:156\u001b[0m, in \u001b[0;36mSMOTETomek._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    153\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy\n\u001b[1;32m--> 156\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmote_\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtomek_\u001b[38;5;241m.\u001b[39mfit_resample(X_res, y_res)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:105\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    103\u001b[0m )\n\u001b[1;32m--> 105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    111\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:360\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[0;32m    359\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mkneighbors(X_class, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 360\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    361\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    362\u001b[0m )\n\u001b[0;32m    363\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n\u001b[0;32m    364\u001b[0m y_resampled\u001b[38;5;241m.\u001b[39mappend(y_new)\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:118\u001b[0m, in \u001b[0;36mBaseSMOTE._make_samples\u001b[1;34m(self, X, y_dtype, y_type, nn_data, nn_num, n_samples, step_size, y)\u001b[0m\n\u001b[0;32m    115\u001b[0m rows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor_divide(samples_indices, nn_num\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    116\u001b[0m cols \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmod(samples_indices, nn_num\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 118\u001b[0m X_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_samples(X, nn_data, nn_num, rows, cols, steps, y_type, y)\n\u001b[0;32m    119\u001b[0m y_new \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(n_samples, fill_value\u001b[38;5;241m=\u001b[39my_type, dtype\u001b[38;5;241m=\u001b[39my_dtype)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_new, y_new\n",
      "File \u001b[1;32mc:\\Users\\syeda\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:185\u001b[0m, in \u001b[0;36mBaseSMOTE._generate_samples\u001b[1;34m(self, X, nn_data, nn_num, rows, cols, steps, y_type, y)\u001b[0m\n\u001b[0;32m    183\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[rows] \u001b[38;5;241m+\u001b[39m steps\u001b[38;5;241m.\u001b[39mmultiply(diffs)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[rows] \u001b[38;5;241m+\u001b[39m steps \u001b[38;5;241m*\u001b[39m diffs\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_new\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 889. MiB for an array with shape (1371519, 85) and data type float64"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "sm = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "rare_classes = [8, 9, 13]\n",
    "\n",
    "y_resampled = y_resampled.replace(rare_classes, 99)   # label 99 = \"RareAttack\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d52228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes:\n",
      "X_train: (2059408, 93) y_train: (2059408,)\n",
      "X_test: (514853, 93) y_test: (514853,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. MEMORY-MAP TRAIN/TEST FILES\n",
    "# ----------------------------------------------------\n",
    "X_train = np.load(\"X_train.npy\", mmap_mode='r').astype(np.float32)\n",
    "y_train = np.load(\"Y_train.npy\", mmap_mode='r').copy() \n",
    "X_test = np.load(\"X_test.npy\", mmap_mode='r').astype(np.float32)\n",
    "y_test = np.load(\"Y_test.npy\", mmap_mode='r').copy()\n",
    "\n",
    "print(\"Original shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4df8e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 8 zero-variance columns: [31, 33, 56, 57, 58, 59, 60, 61]\n",
      "Scaling done.\n",
      "Final train shape: (2059408, 85)\n",
      "Final test shape: (514853, 85)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 2. DROP ZERO-VARIANCE COLUMNS (SCAN COLUMN-WISE)\n",
    "# ----------------------------------------------------\n",
    "zero_var_cols = []\n",
    "for col in range(X_train.shape[1]):\n",
    "    if np.ptp(X_train[:, col]) == 0:  # ptp = max - min\n",
    "        zero_var_cols.append(col)\n",
    "\n",
    "print(f\"Dropping {len(zero_var_cols)} zero-variance columns:\", zero_var_cols)\n",
    "\n",
    "X_train = np.delete(X_train, zero_var_cols, axis=1)\n",
    "X_test = np.delete(X_test, zero_var_cols, axis=1)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. MERGE EXTREMELY RARE CLASSES\n",
    "# ----------------------------------------------------\n",
    "rare_classes = [8, 9, 13]  # Heartbleed, Infiltration, Web Attack SQL inj\n",
    "for cls in rare_classes:\n",
    "    y_train[y_train == cls] = 99\n",
    "    y_test[y_test == cls] = 99\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. STANDARDIZE FEATURES IN BATCHES\n",
    "# ----------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on train\n",
    "# If too large, can batch with partial_fit (here we do in one go for float32)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaling done.\")\n",
    "print(\"Final train shape:\", X_train_scaled.shape)\n",
    "print(\"Final test shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f5311ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Preprocessed files saved.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 5. SAVE PREPROCESSED FILES\n",
    "# ----------------------------------------------------\n",
    "np.save(\"X_train_preprocessed.npy\", X_train_scaled)\n",
    "np.save(\"y_train_preprocessed.npy\", y_train)\n",
    "np.save(\"X_test_preprocessed.npy\", X_test_scaled)\n",
    "np.save(\"y_test_preprocessed.npy\", y_test)\n",
    "\n",
    "print(\"Preprocessing complete. Preprocessed files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
